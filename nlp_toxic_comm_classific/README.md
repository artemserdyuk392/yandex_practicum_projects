# NLP - классификация токсичных комментариев
## Описание проекта
Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 
Нужно обучить модель классифицировать комментарии на позитивные и негативные.
## Навыки и инструменты
**Теги: машинное обучение, CatBoost, downsampling, BERT, Torch, Numpy, Sklearn, SeaBorn, TF-IDF, NLTK, обработка естественного языка**

<img src="https://img.shields.io/badge/Pandas-black?style=flat-square&logo=pandas&logoColor=orange"/><img src="https://img.shields.io/badge/Sklearn-black?style=flat-square&logo=scikitlearn&logoColor=orange"/><img src="https://img.shields.io/badge/MatPlotlib-black?style=flat-square"/>

## Сферы деятельности:
Интернет-сервисы, стартапы
## Основные пункты исследования:
- Загрузил и предобработал данные.
- Лемматизировал текст (используя WordNetLemmatizer и Spacy).
- Использовал downsampling для борьбы с дисбалансом.
- Провёл TF-IDF обработку данных.
- Обучил модель CatBoost.
- Обучил модель LogisticRegression.
- Провёл обработку текста с помощью BERT.
- Обучил модель LogisticRegression.
- Построил confisuon matrix моделей.
- Провел исследование важности признаков для лучшей модели.

Три модели справляются с задачей неплохо, все прошли baseline-порог, но порог проекта в 0.75 прошли только CatBoost TF-IDF и BERT LR.
Сравнив два лемматайзера - Spacy и WordNetLemmaizer, могу сказать, что качество модели после обработки Spacy немного лучше, чем WordNet, но второй, в свою очередь, имеет преимущество по скорости обработки текста.

TF-IDF справляется с задачей в разы быстрее, но ему нужно данных значительно больше, чем для BERT.

Из-за недостатка мощности BERT приходится обучать всего на 300 строках, если иметь более мощное железо - результат окажется лучше.

## Выводы и результаты
F1 score на BERT: 0.9333, F1 score на TF-IDF: 0.75.

Имеется список слов, появление которых значительно повышают вероятность классификации комментария к "токсичному".
